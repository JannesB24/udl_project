{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8754fe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from udl_project.training import config\n",
    "\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32d5bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from udl_project.training.resnet_model_trainer import ResNetModelTrainer\n",
    "\n",
    "res_net_mode_trainer = ResNetModelTrainer(epochs=EPOCHS, learning_rate=config.LEARNING_RATE)\n",
    "res_net_mode_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36e811d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jannes/git/udl_project/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: /home/jannes/.cache/kagglehub/datasets/lara311/flowers-five-classes/versions/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jannes/git/udl_project/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     48\u001b[39m     plt.show()\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# Get class names from the dataset\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m class_names = \u001b[43mtrain_loader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclasses\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mClasses: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     53\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mImage batch shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimages.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'DataLoader' object has no attribute 'classes'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from udl_project.data_handling.data_loader_flowers import DataLoaderFlowers\n",
    "from udl_project.data_handling.flower_dataset import FlowerDataset\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "flower_dataset = FlowerDataset(train_test_spilt=0.8)\n",
    "dataloader = DataLoaderFlowers.create_dataloader(flower_dataset)\n",
    "\n",
    "# Get a batch of training data\n",
    "train_loader = dataloader.get_train_dataloader()\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "\n",
    "# Function to show images\n",
    "def show_augmented_images(images, labels, class_names, num_images=8):\n",
    "    \"\"\"Display a grid of augmented images.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i in range(min(num_images, len(images))):\n",
    "        # Convert tensor to numpy and transpose for matplotlib\n",
    "        img = images[i].clone()\n",
    "\n",
    "        # Clamp values to [0, 1] range\n",
    "        img = torch.clamp(img, 0, 1)\n",
    "\n",
    "        # Convert to numpy and transpose\n",
    "        img_np = img.permute(1, 2, 0).numpy()\n",
    "\n",
    "        axes[i].imshow(img_np)\n",
    "        axes[i].set_title(f\"Class: {class_names[labels[i]]}\")\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Get class names from the dataset\n",
    "class_names = train_loader.classes\n",
    "print(f\"Classes: {class_names}\")\n",
    "print(f\"Image batch shape: {images.shape}\")\n",
    "print(f\"Labels batch shape: {labels.shape}\")\n",
    "\n",
    "# Show the augmented images\n",
    "show_augmented_images(images, labels, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88231f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show multiple augmentations of the same image\n",
    "def show_multiple_augmentations(dataset, image_idx=0, num_augmentations=8):\n",
    "    \"\"\"Show multiple augmented versions of the same image.\"\"\"\n",
    "    # Get the original image and label (before any transforms)\n",
    "    original_img, label = dataset.dataset[image_idx]\n",
    "\n",
    "    # Apply the training transforms multiple times\n",
    "    train_transform = dataloader.train_data.dataset.transform\n",
    "\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i in range(num_augmentations):\n",
    "        # Apply transform to the original image\n",
    "        augmented_img = train_transform(original_img)\n",
    "\n",
    "        # Convert to displayable format\n",
    "        img_display = augmented_img.clone()\n",
    "\n",
    "        img_display = torch.clamp(img_display, 0, 1)\n",
    "        img_np = img_display.permute(1, 2, 0).numpy()\n",
    "\n",
    "        axes[i].imshow(img_np)\n",
    "        axes[i].set_title(f\"Augmentation {i + 1}\")\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    plt.suptitle(f\"Multiple augmentations of the same {class_names[label]} image\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Show multiple augmentations of the same image\n",
    "print(\"Showing multiple augmentations of the same image:\")\n",
    "show_multiple_augmentations(flower_dataset.get_train_dataset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4204c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare original vs augmented images\n",
    "def compare_original_vs_augmented(dataset, num_samples=4):\n",
    "    \"\"\"Compare original images with their augmented versions.\"\"\"\n",
    "    fig, axes = plt.subplots(2, num_samples, figsize=(16, 8))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        # Get original image\n",
    "        original_img, label = dataset.dataset[i]\n",
    "\n",
    "        # Apply augmentation\n",
    "        augmented_img = dataloader.train_data.dataset.transform(original_img)\n",
    "\n",
    "        # Show original image\n",
    "        if isinstance(original_img, torch.Tensor):\n",
    "            orig_np = original_img.permute(1, 2, 0).numpy()\n",
    "        else:\n",
    "            # If PIL image, convert to numpy\n",
    "            orig_np = np.array(original_img)\n",
    "            orig_np = orig_np / 255.0 if orig_np.max() > 1 else orig_np\n",
    "\n",
    "        axes[0, i].imshow(orig_np)\n",
    "        axes[0, i].set_title(f\"Original: {class_names[label]}\")\n",
    "        axes[0, i].axis(\"off\")\n",
    "\n",
    "        # Show augmented image\n",
    "        aug_display = augmented_img.clone()\n",
    "        aug_display = torch.clamp(aug_display, 0, 1)\n",
    "        aug_np = aug_display.permute(1, 2, 0).numpy()\n",
    "\n",
    "        axes[1, i].imshow(aug_np)\n",
    "        axes[1, i].set_title(f\"Augmented: {class_names[label]}\")\n",
    "        axes[1, i].axis(\"off\")\n",
    "\n",
    "    plt.suptitle(\"Original vs Augmented Images\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"Comparing original vs augmented images:\")\n",
    "compare_original_vs_augmented(flower_dataset.get_train_dataset())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
